{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical experiments I (training)\n",
    "\n",
    "### Notebook written by Matteo Sesia and Yaniv Romano\n",
    "#### Stanford University, Department of Statistics\n",
    "#### Last updated on: November 19, 2018\n",
    "\n",
    "The purpose of this notebook is to allow the numerical experiments described in the paper to be reproduced easily.\n",
    "Running this code may take a few hours on a graphical graphical processing unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from DeepKnockoffs import KnockoffMachine\n",
    "from DeepKnockoffs import GaussianKnockoffs\n",
    "import data\n",
    "import parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generating model\n",
    "\n",
    "We model $X \\in \\mathbb{R}^p $ as a multivariate Student's-t distribution, with $p=100$ and the covariance matrix of an auto-regressive process of order one. The default correlation parameter for this distribution is $\\rho =0.5$ and the number of degrees of freedom $\\nu = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features\n",
    "p = 100\n",
    "\n",
    "# Load the built-in multivariate Student's-t model and its default parameters\n",
    "# The currently available built-in models are:\n",
    "# - gaussian : Multivariate Gaussian distribution\n",
    "# - gmm      : Gaussian mixture model\n",
    "# - mstudent : Multivariate Student's-t distribution\n",
    "# - sparse   : Multivariate sparse Gaussian distribution \n",
    "model = \"mstudent\"\n",
    "distribution_params = parameters.GetDistributionParams(model, p)\n",
    "\n",
    "# Initialize the data generator\n",
    "DataSampler = data.DataSampler(distribution_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample $n=10000$ observations of $X$. This dataset will be used later to train a deep knockoff machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated a training dataset of size: 10000 x 100.\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "n = 10000\n",
    "\n",
    "# Sample training data\n",
    "X_train = DataSampler.sample(n)\n",
    "print(\"Generated a training dataset of size: %d x %d.\" %(X_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-order knockoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After computing the empirical covariance matrix of $X$ in the training dataset, we can initialize a generator of second-order knockoffs. The solution of the SDP determines the pairwise correlations between the original variables and the knockoffs produced by this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute pairwise correlation: 0.526.\n"
     ]
    }
   ],
   "source": [
    "# Compute the empirical covariance matrix of the training data\n",
    "SigmaHat = np.cov(X_train, rowvar=False)\n",
    "\n",
    "# Initialize generator of second-order knockoffs\n",
    "second_order = GaussianKnockoffs(SigmaHat, mu=np.mean(X_train,0), method=\"sdp\")\n",
    "\n",
    "# Measure pairwise second-order knockoff correlations \n",
    "corr_g = (np.diag(SigmaHat) - np.diag(second_order.Ds)) / np.diag(SigmaHat)\n",
    "\n",
    "print('Average absolute pairwise correlation: %.3f.' %(np.mean(np.abs(corr_g))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep knockoff machine\n",
    "\n",
    "The default parameters of the machine are set below, as most appropriate for the specific built-in model considered.\n",
    "The figures in the paper were obtained by setting the number of epochs to 1000 and the learning rate to 0.001, while for the sake of simplicity this notebook uses the values 100 and 0.01 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the default hyperparameters for this model\n",
    "training_params = parameters.GetTrainingHyperParams(model)\n",
    "\n",
    "# Set the parameters for training deep knockoffs\n",
    "pars = dict()\n",
    "# Number of epochs\n",
    "pars['epochs'] = 100\n",
    "# Number of iterations over the full data per epoch\n",
    "pars['epoch_length'] = 100\n",
    "# Data type, either \"continuous\" or \"binary\"\n",
    "pars['family'] = \"continuous\"\n",
    "# Dimensions of the data\n",
    "pars['p'] = p\n",
    "# Size of the test set\n",
    "pars['test_size']  = 0\n",
    "# Batch size\n",
    "pars['batch_size'] = int(0.5*n)\n",
    "# Learning rate\n",
    "pars['lr'] = 0.01\n",
    "# When to decrease learning rate (unused when equal to number of epochs)\n",
    "pars['lr_milestones'] = [pars['epochs']]\n",
    "# Width of the network (number of layers is fixed to 6)\n",
    "pars['dim_h'] = int(10*p)\n",
    "# Penalty for the MMD distance\n",
    "pars['GAMMA'] = training_params['GAMMA']\n",
    "# Penalty encouraging second-order knockoffs\n",
    "pars['LAMBDA'] = training_params['LAMBDA']\n",
    "# Decorrelation penalty hyperparameter\n",
    "pars['DELTA'] = training_params['DELTA']\n",
    "# Target pairwise correlations between variables and knockoffs\n",
    "pars['target_corr'] = corr_g\n",
    "# Kernel widths for the MMD measure (uniform weights)\n",
    "pars['alphas'] = [1.,2.,4.,8.,16.,32.,64.,128.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine will be stored in the `tmp/` subdirectory for later use and continuously updated during training after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to store the machine\n",
    "checkpoint_name = \"tmp/\" + model\n",
    "\n",
    "# Where to print progress information\n",
    "logs_name = \"tmp/\" + model + \"_progress.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the machine\n",
    "machine = KnockoffMachine(pars, checkpoint_name=checkpoint_name, logs_name=logs_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the machine to the training data. The value of the loss function on the training will be printed after each epoch, along with other diagnostics based on the MMD, the second moments and the pairwise correlations between variables and knockoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the knockoff machine...\n",
      "[   1/ 100], Loss: 0.1876, MMD: 0.1726, Cov: 1.289, Decorr: 0.299\n",
      "[   2/ 100], Loss: 0.1454, MMD: 0.1366, Cov: 0.927, Decorr: 0.441\n",
      "[   3/ 100], Loss: 0.1332, MMD: 0.1265, Cov: 0.786, Decorr: 0.502\n",
      "[   4/ 100], Loss: 0.1294, MMD: 0.1236, Cov: 0.730, Decorr: 0.536\n",
      "[   5/ 100], Loss: 0.1272, MMD: 0.1220, Cov: 0.702, Decorr: 0.555\n",
      "[   6/ 100], Loss: 0.1260, MMD: 0.1212, Cov: 0.671, Decorr: 0.564\n",
      "[   7/ 100], Loss: 0.1253, MMD: 0.1207, Cov: 0.694, Decorr: 0.567\n",
      "[   8/ 100], Loss: 0.1247, MMD: 0.1204, Cov: 0.680, Decorr: 0.569\n",
      "[   9/ 100], Loss: 0.1238, MMD: 0.1198, Cov: 0.668, Decorr: 0.569\n",
      "[  10/ 100], Loss: 0.1233, MMD: 0.1195, Cov: 0.650, Decorr: 0.572\n",
      "[  11/ 100], Loss: 0.1230, MMD: 0.1194, Cov: 0.651, Decorr: 0.570\n",
      "[  12/ 100], Loss: 0.1225, MMD: 0.1191, Cov: 0.647, Decorr: 0.572\n",
      "[  13/ 100], Loss: 0.1224, MMD: 0.1190, Cov: 0.623, Decorr: 0.570\n",
      "[  14/ 100], Loss: 0.1221, MMD: 0.1189, Cov: 0.633, Decorr: 0.567\n",
      "[  15/ 100], Loss: 0.1220, MMD: 0.1189, Cov: 0.631, Decorr: 0.567\n",
      "[  16/ 100], Loss: 0.1221, MMD: 0.1190, Cov: 0.625, Decorr: 0.564\n",
      "[  17/ 100], Loss: 0.1217, MMD: 0.1187, Cov: 0.612, Decorr: 0.564\n",
      "[  18/ 100], Loss: 0.1217, MMD: 0.1188, Cov: 0.596, Decorr: 0.561\n",
      "[  19/ 100], Loss: 0.1214, MMD: 0.1185, Cov: 0.602, Decorr: 0.560\n",
      "[  20/ 100], Loss: 0.1214, MMD: 0.1186, Cov: 0.592, Decorr: 0.560\n",
      "[  21/ 100], Loss: 0.1212, MMD: 0.1184, Cov: 0.567, Decorr: 0.559\n",
      "[  22/ 100], Loss: 0.1213, MMD: 0.1185, Cov: 0.584, Decorr: 0.559\n",
      "[  23/ 100], Loss: 0.1209, MMD: 0.1183, Cov: 0.572, Decorr: 0.558\n",
      "[  24/ 100], Loss: 0.1214, MMD: 0.1187, Cov: 0.557, Decorr: 0.557\n",
      "[  25/ 100], Loss: 0.1209, MMD: 0.1183, Cov: 0.555, Decorr: 0.554\n",
      "[  26/ 100], Loss: 0.1211, MMD: 0.1185, Cov: 0.548, Decorr: 0.554\n",
      "[  27/ 100], Loss: 0.1211, MMD: 0.1185, Cov: 0.547, Decorr: 0.552\n",
      "[  28/ 100], Loss: 0.1209, MMD: 0.1184, Cov: 0.551, Decorr: 0.551\n",
      "[  29/ 100], Loss: 0.1206, MMD: 0.1181, Cov: 0.541, Decorr: 0.551\n",
      "[  30/ 100], Loss: 0.1208, MMD: 0.1183, Cov: 0.528, Decorr: 0.550\n",
      "[  31/ 100], Loss: 0.1206, MMD: 0.1181, Cov: 0.536, Decorr: 0.546\n",
      "[  32/ 100], Loss: 0.1206, MMD: 0.1181, Cov: 0.537, Decorr: 0.546\n",
      "[  33/ 100], Loss: 0.1205, MMD: 0.1181, Cov: 0.521, Decorr: 0.547\n",
      "[  34/ 100], Loss: 0.1203, MMD: 0.1179, Cov: 0.529, Decorr: 0.549\n",
      "[  35/ 100], Loss: 0.1203, MMD: 0.1179, Cov: 0.528, Decorr: 0.544\n",
      "[  36/ 100], Loss: 0.1205, MMD: 0.1181, Cov: 0.528, Decorr: 0.544\n",
      "[  37/ 100], Loss: 0.1203, MMD: 0.1180, Cov: 0.525, Decorr: 0.543\n",
      "[  38/ 100], Loss: 0.1203, MMD: 0.1179, Cov: 0.522, Decorr: 0.540\n",
      "[  39/ 100], Loss: 0.1206, MMD: 0.1183, Cov: 0.509, Decorr: 0.541\n",
      "[  40/ 100], Loss: 0.1204, MMD: 0.1180, Cov: 0.507, Decorr: 0.540\n",
      "[  41/ 100], Loss: 0.1202, MMD: 0.1179, Cov: 0.510, Decorr: 0.538\n",
      "[  42/ 100], Loss: 0.1204, MMD: 0.1181, Cov: 0.512, Decorr: 0.538\n",
      "[  43/ 100], Loss: 0.1202, MMD: 0.1179, Cov: 0.511, Decorr: 0.536\n",
      "[  44/ 100], Loss: 0.1204, MMD: 0.1181, Cov: 0.507, Decorr: 0.534\n",
      "[  45/ 100], Loss: 0.1202, MMD: 0.1179, Cov: 0.501, Decorr: 0.534\n",
      "[  46/ 100], Loss: 0.1200, MMD: 0.1177, Cov: 0.499, Decorr: 0.533\n",
      "[  47/ 100], Loss: 0.1201, MMD: 0.1179, Cov: 0.500, Decorr: 0.533\n",
      "[  48/ 100], Loss: 0.1201, MMD: 0.1178, Cov: 0.501, Decorr: 0.533\n",
      "[  49/ 100], Loss: 0.1199, MMD: 0.1177, Cov: 0.489, Decorr: 0.534\n",
      "[  50/ 100], Loss: 0.1201, MMD: 0.1179, Cov: 0.484, Decorr: 0.531\n",
      "[  51/ 100], Loss: 0.1199, MMD: 0.1176, Cov: 0.492, Decorr: 0.530\n",
      "[  52/ 100], Loss: 0.1201, MMD: 0.1179, Cov: 0.495, Decorr: 0.531\n",
      "[  53/ 100], Loss: 0.1197, MMD: 0.1174, Cov: 0.491, Decorr: 0.530\n",
      "[  54/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.486, Decorr: 0.529\n",
      "[  55/ 100], Loss: 0.1199, MMD: 0.1177, Cov: 0.484, Decorr: 0.528\n",
      "[  56/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.480, Decorr: 0.529\n",
      "[  57/ 100], Loss: 0.1198, MMD: 0.1176, Cov: 0.480, Decorr: 0.526\n",
      "[  58/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.484, Decorr: 0.526\n",
      "[  59/ 100], Loss: 0.1202, MMD: 0.1180, Cov: 0.480, Decorr: 0.526\n",
      "[  60/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.478, Decorr: 0.524\n",
      "[  61/ 100], Loss: 0.1198, MMD: 0.1176, Cov: 0.487, Decorr: 0.522\n",
      "[  62/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.470, Decorr: 0.523\n",
      "[  63/ 100], Loss: 0.1194, MMD: 0.1173, Cov: 0.486, Decorr: 0.521\n",
      "[  64/ 100], Loss: 0.1199, MMD: 0.1177, Cov: 0.469, Decorr: 0.521\n",
      "[  65/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.471, Decorr: 0.519\n",
      "[  66/ 100], Loss: 0.1197, MMD: 0.1176, Cov: 0.481, Decorr: 0.521\n",
      "[  67/ 100], Loss: 0.1197, MMD: 0.1175, Cov: 0.462, Decorr: 0.520\n",
      "[  68/ 100], Loss: 0.1198, MMD: 0.1176, Cov: 0.473, Decorr: 0.520\n",
      "[  69/ 100], Loss: 0.1198, MMD: 0.1177, Cov: 0.473, Decorr: 0.519\n",
      "[  70/ 100], Loss: 0.1199, MMD: 0.1178, Cov: 0.465, Decorr: 0.516\n",
      "[  71/ 100], Loss: 0.1196, MMD: 0.1175, Cov: 0.467, Decorr: 0.518\n",
      "[  72/ 100], Loss: 0.1199, MMD: 0.1177, Cov: 0.479, Decorr: 0.516\n",
      "[  73/ 100], Loss: 0.1199, MMD: 0.1177, Cov: 0.472, Decorr: 0.516\n",
      "[  74/ 100], Loss: 0.1200, MMD: 0.1178, Cov: 0.462, Decorr: 0.514\n",
      "[  75/ 100], Loss: 0.1196, MMD: 0.1174, Cov: 0.461, Decorr: 0.517\n",
      "[  76/ 100], Loss: 0.1200, MMD: 0.1179, Cov: 0.463, Decorr: 0.514\n",
      "[  77/ 100], Loss: 0.1196, MMD: 0.1175, Cov: 0.464, Decorr: 0.513\n",
      "[  78/ 100], Loss: 0.1194, MMD: 0.1173, Cov: 0.474, Decorr: 0.513\n",
      "[  79/ 100], Loss: 0.1199, MMD: 0.1177, Cov: 0.463, Decorr: 0.513\n",
      "[  80/ 100], Loss: 0.1195, MMD: 0.1174, Cov: 0.462, Decorr: 0.512\n",
      "[  81/ 100], Loss: 0.1194, MMD: 0.1173, Cov: 0.456, Decorr: 0.514\n",
      "[  82/ 100], Loss: 0.1200, MMD: 0.1179, Cov: 0.460, Decorr: 0.508\n",
      "[  83/ 100], Loss: 0.1196, MMD: 0.1175, Cov: 0.470, Decorr: 0.508\n",
      "[  84/ 100], Loss: 0.1197, MMD: 0.1176, Cov: 0.456, Decorr: 0.510\n",
      "[  85/ 100], Loss: 0.1197, MMD: 0.1177, Cov: 0.461, Decorr: 0.509\n",
      "[  86/ 100], Loss: 0.1197, MMD: 0.1176, Cov: 0.465, Decorr: 0.506\n",
      "[  87/ 100], Loss: 0.1193, MMD: 0.1172, Cov: 0.458, Decorr: 0.509\n",
      "[  88/ 100], Loss: 0.1196, MMD: 0.1175, Cov: 0.461, Decorr: 0.507\n",
      "[  89/ 100], Loss: 0.1197, MMD: 0.1176, Cov: 0.459, Decorr: 0.506\n",
      "[  90/ 100], Loss: 0.1195, MMD: 0.1174, Cov: 0.453, Decorr: 0.507\n",
      "[  91/ 100], Loss: 0.1195, MMD: 0.1174, Cov: 0.457, Decorr: 0.507\n",
      "[  92/ 100], Loss: 0.1199, MMD: 0.1178, Cov: 0.450, Decorr: 0.505\n",
      "[  93/ 100], Loss: 0.1192, MMD: 0.1172, Cov: 0.448, Decorr: 0.506\n",
      "[  94/ 100], Loss: 0.1197, MMD: 0.1176, Cov: 0.448, Decorr: 0.503\n",
      "[  95/ 100], Loss: 0.1192, MMD: 0.1172, Cov: 0.448, Decorr: 0.504\n",
      "[  96/ 100], Loss: 0.1195, MMD: 0.1174, Cov: 0.448, Decorr: 0.503\n",
      "[  97/ 100], Loss: 0.1194, MMD: 0.1174, Cov: 0.447, Decorr: 0.503\n",
      "[  98/ 100], Loss: 0.1192, MMD: 0.1172, Cov: 0.456, Decorr: 0.504\n",
      "[  99/ 100], Loss: 0.1195, MMD: 0.1174, Cov: 0.458, Decorr: 0.502\n",
      "[ 100/ 100], Loss: 0.1195, MMD: 0.1174, Cov: 0.441, Decorr: 0.503\n"
     ]
    }
   ],
   "source": [
    "# Train the machine\n",
    "print(\"Fitting the knockoff machine...\")\n",
    "machine.train(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
